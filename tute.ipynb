{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 1. Get Data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = 'C:/Users/thanh/Documents/CARS/Data/ml-100k/'\n",
    "df = pd.read_csv(path+ 'u.data', sep = '\\t', names=['userID','itemID','rating','timestamp'])\n",
    "df2= pd.read_csv(path+ 'u.genre', sep = '|',names=['Genres','ID'])\n",
    "df3=pd.read_csv(path+ 'u.item', sep = '|',encoding = \"ISO-8859-1\",names=['MovieID','Title','realeasDate','videoReleaseDate','URL','unknown','Action','Adventure', 'Animation',  'Children' , 'Comedy',  'Crime',  'Documentary',  'Drama',  'Fantasy',  'Film-Noir',  'Horror',  'Musical',  'Mystery',  'Romance',  'Sci-Fi',  'Thriller',  'War',  'Western' ])\n",
    "df = df[:800]\n",
    "df3 = df3.drop(columns=['Title','realeasDate','videoReleaseDate','URL'])\n",
    "data = pd.merge(df,df3, left_on='itemID',right_on='MovieID',how='inner').drop(columns='MovieID') #Input for side-info\n",
    "#number of attributes for feaure \"GENRE\"\n",
    "F_genre = len(data.columns)-4\n",
    "df3 = df3.set_index('MovieID')\n",
    "zzx = data.groupby(['itemID']).mean().drop(columns=['userID','rating','timestamp']).T\n",
    "# zzx.columns = zzx.iloc[0]\n",
    "# zzx = zzx[1:]\n",
    "rating=data.pivot(index='userID',columns='itemID',values='rating').fillna(0)\n",
    "rate = rating.reset_index().drop(columns=['userID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "class MatrixFactorizationCF:\n",
    "    def __init__(self, n_factors, lambda_reg, n_iterations, alpha):\n",
    "        self.n_factors = n_factors\n",
    "        self.lambda_reg = lambda_reg\n",
    "        self.n_iterations = n_iterations\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def fit(self, X, item_features):\n",
    "        model = NMF(n_components=self.n_factors)\n",
    "        self.n_users, self.n_items = X.shape\n",
    "        self.R = coo_matrix(X)\n",
    "        self.item_features = item_features\n",
    "        self.U = model.fit_transform(self.R)\n",
    "        self.V = model.components_\n",
    "        self.item_feature_weights = np.random.normal(size=(self.n_items, self.item_features.shape[1]))\n",
    "        self.item_feature_bias = np.random.normal(size=self.n_items)\n",
    "        \n",
    "        for i in tqdm(range(self.n_iterations)):\n",
    "            self.update_user_factors()\n",
    "            self.update_item_factors()\n",
    "            self.update_item_feature_weights()\n",
    "            self.update_item_feature_bias()\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return self.U.dot(self.V.T) + self.item_features.dot(self.item_feature_weights.T) + self.item_feature_bias\n",
    "        \n",
    "    def update_user_factors(self):\n",
    "        VV = self.V.T.dot(self.V)\n",
    "        for i in range(self.n_users):\n",
    "            V_i = self.V[self.R.row[self.R.row == i], :]\n",
    "            A = V_i.T.dot(V_i) + self.lambda_reg * np.eye(self.n_factors)\n",
    "            b = V_i.T.dot(self.R.data[self.R.row == i]) + self.alpha * self.U[i, :]\n",
    "            self.U[i, :] = np.linalg.solve(A, b)\n",
    "    \n",
    "    def update_item_factors(self):\n",
    "        UU = self.U.T.dot(self.U)\n",
    "        for j in range(self.n_items):\n",
    "            U_j = self.U[self.R.col[self.R.col == j], :]\n",
    "            A = U_j.T.dot(U_j) + self.lambda_reg * np.eye(self.n_factors)\n",
    "            b = U_j.T.dot(self.R.data[self.R.col == j]) + self.alpha * (self.V[j, :] + self.item_features[j, :].dot(self.item_feature_weights))\n",
    "            self.V[j, :] = np.linalg.solve(A, b)\n",
    "    \n",
    "    def update_item_feature_weights(self):\n",
    "        for j in range(self.n_items):\n",
    "            sim = cosine_similarity(self.item_features[j, :].reshape(1, -1), self.item_features)\n",
    "            w = sim.dot(self.V) / sim.sum()\n",
    "            A = w.T.dot(w) + self.lambda_reg * np.eye(self.n_factors)\n",
    "            b = w.T.dot(self.R.data[self.R.col == j] - self.V[j, :].dot(self.U[self.R.row[self.R.col == j], :].T))\n",
    "            self.item_feature_weights[j, :] = np.linalg.solve(A, b)\n",
    "    \n",
    "    def update_item_feature_bias(self):\n",
    "        for j in range(self.n_items):\n",
    "            self.item_feature_bias[j] = (self.R.data[self.R.col == j] - self.U[self.R.row[self.R.col == j], :].dot(self.V[j, :].T) - self.item_features[j, :].dot(self.item_feature_weights.T)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = MatrixFactorizationCF(n_factors=10,lambda_reg=0.4,alpha=0.012,n_iterations=250)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch Packages\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class MF(nn.Module):\n",
    "    # Iteration counter\n",
    "    itr = 0\n",
    "\n",
    "    def __init__(self, n_user, n_item, n_occu, k=10, c_vector=1.0, c_bias=1.0, writer=None):\n",
    "        \"\"\"\n",
    "        :param n_user: User column\n",
    "        :param n_item: Item column\n",
    "        :param n_occu: Occupation column\n",
    "        :param k: Dimensions constant\n",
    "        :param c_vector: Regularization constant\n",
    "        :param c_bias: Regularization constant for the biases\n",
    "        :param writer: Log results via TensorBoard\n",
    "        \"\"\"\n",
    "        super(MF, self).__init__()\n",
    "\n",
    "        # This will hold the logging\n",
    "        self.writer = writer\n",
    "\n",
    "        # These are the hyper-parameters\n",
    "        self.k = k\n",
    "        self.n_user = n_user\n",
    "        self.n_item = n_item\n",
    "        self.n_occu = n_occu\n",
    "        self.c_bias = c_bias\n",
    "        self.c_vector = c_vector\n",
    "\n",
    "        # The embedding matrices for user and item are learned and fit by PyTorch\n",
    "        self.user = nn.Embedding(n_user, k)\n",
    "        self.item = nn.Embedding(n_item, k)\n",
    "\n",
    "        # We've added new term here: Embedding matrices for occupation vectors\n",
    "        self.occu = nn.Embedding(n_occu, k)\n",
    "\n",
    "        # Embedding matrices for the user's biases and the item's biases\n",
    "        self.bias_user = nn.Embedding(n_user, 1)\n",
    "        self.bias_item = nn.Embedding(n_item, 1)\n",
    "\n",
    "        # Initialize the bias tensors\n",
    "        self.bias = nn.Parameter(torch.ones(1))\n",
    "\n",
    "    def __call__(self, train_x):\n",
    "        \"\"\"This is the most important function in this script\"\"\"\n",
    "        # These are the user indices, and correspond to \"u\" variable\n",
    "        user_id = train_x[:, 0]\n",
    "        # These are the item indices, correspond to the \"i\" variable\n",
    "        item_id = train_x[:, 1]\n",
    "\n",
    "        # Initialize a vector user = p_u using the user indices\n",
    "        vector_user = self.user(user_id)\n",
    "        # Initialize a vector item = q_i using the item indices\n",
    "        vector_item = self.item(item_id)\n",
    "\n",
    "        # The user-item interaction: p_u * q_i is a dot product between the user vector and the item vector\n",
    "        ui_interaction = torch.sum(vector_user * vector_item, dim=1)\n",
    "\n",
    "        # Pull out biases\n",
    "        bias_user = self.bias_user(user_id).squeeze()\n",
    "        bias_item = self.bias_item(item_id).squeeze()\n",
    "        biases = (self.bias + bias_user + bias_item)\n",
    "\n",
    "        # These are the occupation indices, and correspond to \"o\" variable\n",
    "        occu_id = train_x[:, 3]\n",
    "        # Initialize a vector occupation = r_o using the occupation indices\n",
    "        vector_occu = self.occu(occu_id)\n",
    "        # The user-occupation interaction: p_u * r_o is a dot product between the user vector and the occupation vector\n",
    "        uo_interaction = torch.sum(vector_user * vector_occu, dim=1)\n",
    "\n",
    "        # Add the bias, the user-item interaction, and the user-occupation interaction to obtain the final prediction\n",
    "        prediction = ui_interaction + uo_interaction + biases\n",
    "        return prediction\n",
    "\n",
    "    def loss(self, prediction, target):\n",
    "        \"\"\"\n",
    "        Function to calculate the loss metric\n",
    "        \"\"\"\n",
    "        # Calculate the Mean Squared Error between target and prediction\n",
    "        loss_mse = F.mse_loss(prediction.squeeze(), target.squeeze())\n",
    "\n",
    "        # Compute L2 regularization over the biases for user and the biases for item matrices\n",
    "        prior_bias_user = l2_regularize(self.bias_user.weight) * self.c_bias\n",
    "        prior_bias_item = l2_regularize(self.bias_item.weight) * self.c_bias\n",
    "\n",
    "        # Compute L2 regularization over user (P) and item (Q) matrices\n",
    "        prior_user = l2_regularize(self.user.weight) * self.c_vector\n",
    "        prior_item = l2_regularize(self.item.weight) * self.c_vector\n",
    "\n",
    "        # Compute L2 regularization over occupation (R) matrices\n",
    "        prior_occu = l2_regularize(self.occu.weight) * self.c_vector\n",
    "\n",
    "        # Add up the MSE loss + user & item regularization + user & item biases regularization + occupation\n",
    "        # regularization\n",
    "        total = loss_mse + prior_user + prior_item + prior_bias_item + prior_bias_user + prior_occu\n",
    "\n",
    "        # This logs all local variables to tensorboard\n",
    "        for name, var in locals().items():\n",
    "            if type(var) is torch.Tensor and var.nelement() == 1 and self.writer is not None:\n",
    "                self.writer.add_scalar(name, var, self.itr)\n",
    "        return total\n",
    "\n",
    "\n",
    "def l2_regularize(array):\n",
    "    \"\"\"\n",
    "    Function to do L2 regularization\n",
    "    \"\"\"\n",
    "    loss = torch.sum(array ** 2.0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3a18842cd88223d2eea50a134bb96e0584ccfa9a42436ff53b4efa05bbcefc4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
